    <!DOCTYPE html>
<html lang="en-us">
	<head>
		<meta charset="utf-8">
		<meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1">
		<meta name="viewport" content="width=device-width, initial-scale=1">
		<meta name="author" content="Jorge Vicente Cantero">
		
		<meta name="generator" content="Hugo 0.40.3" />
		<title>Reduce compile times of macros and implicits &middot; jvican</title>
		<link rel="shortcut icon" href="https://jvican.github.io/images/favicon.ico">
		<link rel="stylesheet" href="https://jvican.github.io/css/style.css">
		<link rel="stylesheet" href="https://jvican.github.io/css/highlight.css">
		

		
		<link rel="stylesheet" href="https://jvican.github.io/css/monosocialiconsfont.css">
		

		
		<link href="https://jvican.github.io/index.xml" rel="alternate" type="application/rss+xml" title="jvican" />
		

		<meta property="og:title" content="Reduce compile times of macros and implicits" />
<meta property="og:description" content="A tour on profiling compilation times to understand the cost of automatic typeclass derivation with a focus on Shapeless." />
<meta property="og:type" content="article" />
<meta property="og:url" content="https://jvican.github.io/post/reduce-compile-times/" />



<meta property="article:published_time" content="2018-05-20T10:00:00&#43;01:00"/>

<meta property="article:modified_time" content="2018-05-20T10:00:00&#43;01:00"/>











	    
	    
<meta itemprop="name" content="Reduce compile times of macros and implicits">
<meta itemprop="description" content="A tour on profiling compilation times to understand the cost of automatic typeclass derivation with a focus on Shapeless.">


<meta itemprop="datePublished" content="2018-05-20T10:00:00&#43;01:00" />
<meta itemprop="dateModified" content="2018-05-20T10:00:00&#43;01:00" />
<meta itemprop="wordCount" content="8292">



<meta itemprop="keywords" content="" />

	    <meta name="twitter:card" content="summary"/>
<meta name="twitter:title" content="Reduce compile times of macros and implicits"/>
<meta name="twitter:description" content="A tour on profiling compilation times to understand the cost of automatic typeclass derivation with a focus on Shapeless."/>
<meta name="twitter:site" content="@https://www.twitter.com/jvican"/>

	</head>

    <body>
       <nav class="main-nav">
	
	
		<a href='https://jvican.github.io/'> <span class="arrow">‚Üê</span>Home</a>
	

	
		<a href='https://jvican.github.io/about'>About me</a>
	

	
	<a class="cta" href="https://jvican.github.io/index.xml">Subscribe</a>
	
</nav>

        <section id="wrapper">
            <article class="post">
                <header>
                    <h1>Reduce compile times of macros and implicits</h1>
                    <h2 class="headline">
                    May 20, 2018 
                    <br>
                    
                    </h2>
                </header>
                <section id="post-body">
                    

<p>Today I explain how I&rsquo;ve reduced compilation times dramatically
in one of the projects I&rsquo;ve been working for the past months.
This project uses automatic typeclass derivation via Shapeless and I believe
the optimizations here presented can be migrated to other Scala projects too.</p>

<p>My goal is to explain how I:</p>

<ol>
<li>identified the bottleneck of compilation;</li>
<li>profiled the compilation time of my application; and,</li>
<li>changed a few lines of code to get <em>much</em> better compile times.</li>
</ol>

<p>A major part of this post goes to discussing <strong>the cost of implicit search
and macro expansions</strong>, describe what automatic typeclass derivation is and
why both slow down compilation times.</p>

<p>After reading the blog post, you should understand:</p>

<ul>
<li>Why Shapeless-based code is prone to slow compilation times.</li>
<li>How you can replicate a similar analysis of compilation times on code that
abuses implicit searches and macros.</li>
<li>How implicit search and macros interact in unexpected ways that hurt
productivity and how you can optimize their interaction.</li>
<li>Why semi-automatic typeclass derivation is preferred over automatic typeclass
derivation, and how the latter should only be used with extreme care.</li>
</ul>

<p>The most important take-away from this guide is that <strong>you should not take
slow Scala compilation times for granted</strong>.</p>

<p>In most of the cases, slow compilations originate from either an
unintentional misuse of a macro-based library, or an inefficient
implementation of a macro. You better catch them early so that they don&rsquo;t
kill the productivity of your team.</p>

<h2 id="tl-dr">TL;DR</h2>

<p>We use a compiler plugin (<code>scalac-profiling</code>) and the new statistics
infrastructure merged in Scala <code>2.12.5</code> to achieve speedups of 8x in the
compilation time of one of the modules of
<a href="https://scalacenter.github.io/bloop/">Bloop</a>, an application that makes an
intense use of automatic typeclass derivation via Shapeless.</p>

<p>You can expect similar speedups in either applications that rely on Shapeless
to do automatic typeclass derivation or applications that make a heavy use of
implicits and macros.</p>

<p>This is a blog post rich in details and so it may take you some time to
digest fully. If you&rsquo;re only interested in the TL;DR version and are already
familiar with the causes of slow compilation times in Shapeless-like code,
skip the context and <a href="#the-cost-of-implicit-macros">check out directly the detective work</a>.</p>

<p>If you want to apply the same procedure in your project, reading the whole
blog post is <strong>highly recommended</strong>.</p>

<p>The <a href="#conclusion">Conclusion</a> sums up all we&rsquo;ve achieved
throught the blog post, though the interesting bits are in the details.</p>

<p>This is a long blog post. Put on your profiling hat and let&rsquo;s get our hands
dirty!</p>

<h2 id="the-codebase">The codebase</h2>

<p><a href="https://github.com/scalacenter/bloop">Bloop</a> is a <em>build-tool-agnostic</em>
compilation server with a focus on developer productivity that I develop at
the Scala Center together with <a href="https://github.com/Duhemm">Martin Duhem</a>. It
gives you about ~20-25% faster compilation times than sbt, and we plan on
further improving the performance of both batch and incremental compilation
in the next month.</p>

<p>Bloop is a small codebase with 10000 lines of Scala code.</p>

<pre><code class="language-bash">jvican in /data/rw/code/scala/loop                                                                                                                                                                   [22:53:34] 
&gt; $ loc --exclude zinc/* --exclude benchmark-bridge/*
-----------------------------------------------------------
 Language    Files     Lines     Blank   Comment    Code
-----------------------------------------------------------
 Scala         129     12383      1597      1210      9576
 JavaScript     30     12264      1643      1519      9102
 Markdown       72      9132      1079         0      8053
 CSS            10      5117       750        47      4320
 JSON           49      3028        10         0      3018
 Java           46      5576       825      1998      2753
 Python          4      1407       212        71      1124
 HTML           34      1223        74        47      1102
 C               1       899       133       184       582
 XML             5       285        26         2       257
 Bourne Shell    8       249        43        19       187
 Plain Text      1       203        33         0       170
 Protobuf        1       151        32        20        99
 Toml            3        83         5         2        76
 Makefile        2        39         7         8        24
 YAML            1        24         6         1        17
-----------------------------------------------------------
 Total         396     52063      6475      5128     40460
-----------------------------------------------------------
</code></pre>

<p>It has three main submodules:</p>

<ol>
<li><code>jsonConfig</code>: the module that defines the JSON schema of the configuration files.</li>
<li><code>backend</code>: the module that defines the compiler-specific data structures and integrations.</li>
<li><code>frontend</code>: the high level code that defines the internal task engine and nailgun integration.</li>
</ol>

<p>The two first modules are lightweight and fast to compile. In a hot compiler,
their batch compilations take 2 or 3 seconds. However, compiling <code>frontend</code>
is more than 20x slower. This slowness is surprising given that <code>frontend</code> is
only about 6000 LOC, so <a href="https://developer.lightbend.com/blog/2017-06-12-faster-scala-compiler/">in
theory</a>
it should compile in ~4 seconds.</p>

<p><code>frontend</code> depends on
<a href="https://github.com/alexarchambault/case-app/"><code>case-app</code></a>, a command-line
parsing library for Scala that uses
<a href="https://github.com/milessabin/shapeless">Shapeless</a>. In our case, the reason
why the compilation takes 30 seconds.</p>

<p>Waiting 30 seconds for a change to take effect (even under incremental
compilation) is a no-go. It may not seem much, but this kind of wait kills
productivity and gets me out of the zone. That affects my decision-making
process a big deal.</p>

<p>In the past, I&rsquo;ve also noticed that a slow workflow discourages me from
adding complete test suites (the more tests I add the more I need to wait to
compile) or making experiments in the code. That has rendered my experience
as a Scala developer less pleasant.</p>

<p>But this time I decided to fight Bloop compilation times, and documented my
experience so that you can too.</p>

<h2 id="the-setup-and-workflow">The setup and workflow</h2>

<p>To profile Bloop compilation times, we use Bloop itself to make sure that we
preserve hot compilers across all runs. You should be able to replicate the results
with sbt too, but make sure that every time you <code>reload</code> the build you warm
up the compiler at least 10 times.</p>

<p>To set up Bloop as a user, follow the installation instructions in <a href="https://scalacenter.github.io/bloop/">our
website</a>. You only need to install
Bloop and start the server. You then clone the Bloop codebase and generate
the configuration files.</p>

<pre><code class="language-bash">git clone https://github.com/scalacenter/bloop
git submodule update --init
git checkout v1.0.0-M10
sbt bloopInstall
</code></pre>

<p>After that, running <code>bloop about</code> in the base directory of the Bloop codebase should work.</p>

<pre><code class="language-bash">jvican in /data/rw/code/scala/loop
&gt; $ bloop about
  _____            __         ______           __
 / ___/_________ _/ /___ _   / ____/__  ____  / /____  _____
 \__ \/ ___/ __ `/ / __ `/  / /   / _ \/ __ \/ __/ _ \/ ___/
___/ / /__/ /_/ / / /_/ /  / /___/ /__/ / / / /_/ /__/ /
____/\___/\__,_/_/\__,_/   \____/\___/_/ /_/\__/\___/_/

Bloop-frontend is made with love at the Scala Center &lt;3

Bloop-frontend version    `1.0.0-M10`
Zinc version              `1.1.7+62-0f4ad9d5`
Scala version             `2.12.4`

It is maintained by Martin Duhem, Jorge Vicente Cantero.
</code></pre>

<h3 id="compiling-the-codebase">Compiling the codebase</h3>

<p>All we&rsquo;ll do in the next sections is to compile the codebase several times
and see how the compilation times behave after applying our changes.</p>

<p>I recommend cleaning and compiling <code>frontend</code> sequentially at least 10 times
to get a stable hot compiler. After that, we&rsquo;ll do incremental compilation in
the files we change. I&rsquo;ve done this for convenience; you should be able to
replicate the results with full compilation.</p>

<h4 id="warm-up-the-compiler">Warm up the compiler</h4>

<pre><code class="language-bash">for i in {1..10}; do
  echo &quot;Warming up the compiler; iteration $i&quot;
  bloop clean frontend
  bloop compile frontend
done
</code></pre>

<h2 id="the-analysis">The analysis</h2>

<p>The first step to analyze your compilation times is that you set your
intuitions aside. We&rsquo;re going to look at the raw compiler data with fresh
eyes and see where that leads us.</p>

<p>If you try to validate previously-formed assumptions, it&rsquo;s likely you&rsquo;ll be
misled by the data. I&rsquo;ve been there, so don&rsquo;t fall into the same trap.</p>

<p>Profiling compilation times requires dedicated tools. There isn&rsquo;t much we can
get from using profilers like Yourkit or Java Flight Recorder because they show
the result of the inefficiencies, not the cause.</p>

<p>There are cases when knowing the hot methods, inspecting the heap or studying
GC statistics is useful. I&rsquo;ve used this data in the past to find and fix
inefficiencies in the compiler. However, this guide is only concerned about
the misuse of language features, and so we need to take a higher-level
profiling approach.</p>

<h3 id="compiler-statistics">Compiler statistics</h3>

<p>The compiler has built-in support for statistics <em>from 2.12.5 on</em>. This work
resulted from <a href="https://github.com/scalacenter/advisoryboard/blob/master/proposals/010-compiler-profiling.md">a Scala Center Advisory Board
proposal</a>
about compiler profiling. Morgan Stanley, the creator of the document,
proposed the Scala Center to develop tools to help diagnose compilation
bottlenecks.</p>

<hr />

<p>(For those that don&rsquo;t know how we work, Advisory Board members can make
project recommendations to the Scala Center. Every member encourages action
on the problems that are most important to them, and we take those
recommendations into account when deciding how to allocate our resources.
Donating to the Scala Center has its perks; your voice as a Scala shop can be
heard and we can work to fix the things that upset you and the Scala
community.)</p>

<p>Back then, I was interested in this topic and so the proposal was assigned to me.
My work on the compiler revolved around fixing the broken
implementation of statistics in 2.11.x and reducing the instrumentation
overhead. Afterwards, I created the tooling I use in this guide to profile
Scala programs.</p>

<hr />

<p>Compiler statistics have both timers and counters that record data about
expensive compiler operations like subtype checks, finding members, implicit
searches, macro expansion, class file loading, et cetera. This data is the
perfect starting point to have a high-level idea of what&rsquo;s going on.</p>

<h4 id="setting-statistics-up">Setting statistics up</h4>

<p>Enable compiler statistics by adding the <code>-Ystatistics</code> compiler flag to the
project you want to benchmark. <em>Note that you need to use Scala 2.12.5 or
above</em>. I <strong>highly</strong> recommend using the latest version. At the moment of
this writing, that&rsquo;s <code>2.12.6</code>.</p>

<p>Add the compiler flag to the field <code>options</code> inside the
<code>.bloop/frontend.json</code> json configuration file. When you save, Bloop will
automatically pick up your changes and add the compiler option without the
need of a <code>reload</code>.</p>

<p>Run <code>bloop compile frontend -w --reporter scalac</code> (we use the default scalac
reporter for clarity) and have a look at the data. The output of the
compilation will be <a href="/images/bloop-compile-0.txt">similar to this log</a>.
Check the end of it. You should see a report of compilation time spent per
phase.</p>

<pre><code>*** Cumulative timers for phases
#total compile time      : 1 spans, ()32545.975ms
  parser                 : 1 spans, ()65.017ms (0.2%)
  namer                  : 1 spans, ()42.827ms (0.1%)
  packageobjects         : 1 spans, ()0.187ms (0.0%)
  typer                  : 1 spans, ()27432.596ms (84.3%)
  patmat                 : 1 spans, ()1169.028ms (3.6%)
  superaccessors         : 1 spans, ()36.02ms (0.1%)
  extmethods             : 1 spans, ()3.548ms (0.0%)
  pickler                : 1 spans, ()9.449ms (0.0%)
  xsbt-api               : 1 spans, ()159.278ms (0.5%)
  xsbt-dependency        : 1 spans, ()94.846ms (0.3%)
  refchecks              : 1 spans, ()627.633ms (1.9%)
  uncurry                : 1 spans, ()408.305ms (1.3%)
  fields                 : 1 spans, ()414.151ms (1.3%)
  tailcalls              : 1 spans, ()38.455ms (0.1%)
  specialize             : 1 spans, ()184.562ms (0.6%)
  explicitouter          : 1 spans, ()80.488ms (0.2%)
  erasure                : 1 spans, ()624.472ms (1.9%)
  posterasure            : 1 spans, ()63.249ms (0.2%)
  lambdalift             : 1 spans, ()125.944ms (0.4%)
  constructors           : 1 spans, ()47.109ms (0.1%)
  flatten                : 1 spans, ()46.527ms (0.1%)
  mixin                  : 1 spans, ()59.808ms (0.2%)
  cleanup                : 1 spans, ()42.336ms (0.1%)
  delambdafy             : 1 spans, ()47.771ms (0.1%)
  jvm                    : 1 spans, ()714.008ms (2.2%)
  xsbt-analyzer          : 1 spans, ()5.175ms (0.0%)
</code></pre>

<p>The report suggests that about <strong>84.3% of the compilation time</strong> is spent on
typer. This is an unusual high value. Typechecking a normal project is
expected to take around 50-70% of the whole compilation time.</p>

<p>If you have a higher number than the average, then it most likely means
you&rsquo;re pushing the typechecker hard in some unexpected way, and you should
keep on the exploration.</p>

<h3 id="walking-into-the-lion-s-den">Walking into the lion&rsquo;s den</h3>

<p>Now that the data signals a bottleneck in typer, let&rsquo;s keep our statistics
log short and enable <code>-Ystatistics:typer</code>. That will report only statistics
produced during typing.</p>

<p>We then run compilation again. The logs contain information about timers and
counters of several places in the typechecker. These timers and counters help
you know how you&rsquo;re stressing the compiler.</p>

<p>If the compilation of your program requires an unusual amount of subtype
checks, <code>time spent in &lt;:&lt;</code> will be high. There are no normal values for
subtype checks &ndash;the time spent here depends on a lot of factors&ndash; but an
abnormal value would be anything above 15% of the whole typechecking time.</p>

<p>The first thing we notice when studying the logs is that typechecking
<code>frontend</code> takes 28 seconds. We also see some unusual values for the
following counters:</p>

<pre><code class="language-json">#class symbols             : 1842246
#typechecked identifiers   : 134734
#typechecked selections    : 225020
#typechecked applications  : 82421
</code></pre>

<p>The Scala compiler creates almost two million class symbols (!) and
typechecks 134734 identifiers, almost the double of selections and half of
applications. Those are pretty high values. That begs the question: why are
we creating so many classes?</p>

<p>Next, we check time spent in common typechecking operations:</p>

<pre><code>time spent in lubs         : 67 spans, ()63.194ms (0.2%) aggregate, 16.29ms (0.1%) specific
time spent in &lt;:&lt;          : 1548620 spans, ()1791.068ms (6.5%) aggregate, 1583.94ms (5.8%) specific
time spent in findmember   : 873498 spans, ()638.792ms (2.3%) aggregate, 592.663ms (2.2%) specific
time spent in findmembers  : 0 spans, ()0.0ms (0.0%) aggregate, 0.0ms (0.0%) specific
time spent in asSeenFrom   : 2541823 spans, ()1299.199ms (4.7%) aggregate, 1238.814ms (4.5%) specific
</code></pre>

<p><code>time spent in lubs</code> should be high whenever you use lots of pattern matching
or if expressions, and the compiler needs to lub (find the common type of a
sequence of types &ndash; also called finding &ldquo;least upper bound&rdquo; among some
types). Eugene Yokota explains it well <a href="http://eed3si9n.com/stricter-scala-with-ynolub">in this well-aged blog
post</a>.</p>

<p><code>time spent in findmember</code> and it&rsquo;s sister <code>time spent in findmembers</code> should
be up in the profiles whenever you have deep class hierarchies and lots of
overridden methods.</p>

<p><code>time spent in asSeenFrom</code> is high whenever your code makes a heavy use of
dependent types, type projections or abstract types in a more general way.</p>

<p>In the case of <code>frontend</code>, the durations of all these operations are
reasonable, which hints us that the inefficiency is elsewhere.</p>

<p>(For most of the cases, these timers are unlikely to be high when typechecking
your program. If they are, try to figure out why and file a ticket in
<code>scala/bug</code> so that either I or the Scala team can look into it.)</p>

<h3 id="the-troublemaker">The troublemaker</h3>

<p>Most of the projects that suffer from compilation times abuse or misuse
either macros (for example, inefficient macro implementations that do a lot
of <code>typecheck</code>/<code>untypecheck</code>), implicit searches (for example, misplaced
implicit instances that take too long to find) or a combination of both.</p>

<p>It&rsquo;s difficult to miss how long macro expansion and implicit searches take in
the compilation of <code>frontend</code>, and how the values seem to be highly
correlated.</p>

<pre><code>time spent implicits   : 33609 spans, ()26808.491ms (97.7%)
  successful in scope  : 346 spans, ()71.931ms (0.3%)
  failed in scope      : 33263 spans, ()3195.452ms (11.6%)
  successful of type   : 18286 spans, ()26730.255ms (97.4%)
  failed of type       : 14977 spans, ()17370.235ms (63.3%)
  assembling parts     : 18647 spans, ()374.562ms (1.4%)
  matchesPT            : 136322 spans, ()505.763ms (1.8%)
time spent macroExpand : 44445 spans, ()26451.132ms (96.4%)
</code></pre>

<p>This is a red flag. We expand around 44500 macro expansions (!) and spend
almost the totality of the macro expansion time searching for implicits.
We have our troublemaker.</p>

<h3 id="an-initial-exploration-of-the-data">An initial exploration of the data</h3>

<p>How do we know which implicit searches are the most expensive? What are the
macro expansions that dominate the compile time?</p>

<p>The data we get from <code>-Ystatistics</code> doesn&rsquo;t help us answer these questions,
even though they are fundamental to our analysis. As users, we treat macros
as blackboxes &mdash;mere building blocks of our library or application&mdash; and
now we need to unravel them.</p>

<h4 id="a-profiling-plugin-for-scalac">A profiling plugin for <code>scalac</code></h4>

<p>To answer the previous questions, we&rsquo;re going to use
<a href="https://github.com/scalacenter/scalac-profiling">scalac-profiling</a>, a
compiler plugin that exposes more profiling data to Scala developers.</p>

<p>I wrote the plugin with three goals in mind:</p>

<ul>
<li>Expose a common file format that encapsulates all the compilation profiling
data, called <code>profiledb</code>.</li>
<li>Use visual tools to ease analysis of the data (e.g. flamegraphs).</li>
<li>Allow third parties to develop tooling to integrate this data in IDEs and editors.
There is a rough <code>vscode</code> prototype working.</li>
</ul>

<p>The compiler plugin hooks into several parts of the compiler to extract
information related to implicit search and macro expansion. This data will
prove instrumental to understand the interaction between both features.</p>

<p>Install <code>scalac-profiling</code> by fetching the <code>1.0.0</code> release.</p>

<pre><code class="language-bash">&gt; $ coursier fetch --intransitive ch.epfl.scala:scalac-profiling_2.12:1.0.0
https://repo1.maven.org/maven2/ch/epfl/scala/scalac-profiling_2.12/6cac8b23/scalac-profiling_2.12-6cac8b23.jar
  100.0% [##########] 4.1 MiB (2.1 MiB / s)
/home/jvican/.coursier/cache/v1/https/oss.sonatype.org/content/repositories/staging/ch/epfl/scala/scalac-profiling_2.12/1.0.0/scalac-profiling_2.12-1.0.0.jar
</code></pre>

<p>Then open the <code>frontend</code>&rsquo;s bloop configuration file and add the following
compiler options in the <code>options</code> field. Note that <code>-Xplugin</code> contains the
<code>$PATH_TO_PLUGIN_JAR</code> variable which you must replace with the resolved
artifact from coursier. Replace <code>$BLOOP_CODEBASE_DIRECTORY</code> by the base
directory of the cloned bloop repository.</p>

<pre><code class="language-json">  &quot;-Ycache-plugin-class-loader:last-modified&quot;,
  &quot;-Xplugin:$PATH_TO_PLUGIN_JAR&quot;,
  &quot;-P:scalac-profiling:no-profiledb&quot;,
  &quot;-P:scalac-profiling:show-profiles&quot;,
  &quot;-P:scalac-profiling:sourceroot:$BLOOP_CODEBASE_DIRECTORY&quot;
</code></pre>

<p>The first two flags set up the compiler plugin.</p>

<p>The flag <code>no-profiledb</code> disables the generation of <code>profiledb</code>s and
<code>sourceroot</code> tells the plugin the base directory of the project. The
profiledb is only required when we process the data with other tools, so by
disabling it we keep the overhead of the plugin to the bare minimum.</p>

<p>The flag <code>show-profiles</code> displays the following data in the compilation logs:</p>

<ul>
<li>Implicit searches by position. Useful to know how many implicit searches were
triggered per position.</li>
<li>Implicit searches by type. Essential data to know how many implicit searches
were performed for a given type and how much time they took.</li>
<li>Repeated macro expansions. An optimistic counter that tells us how many of
the macros returned the same stringified AST nodes and could therefore be
cached across all use-sites (in the macro implementation).</li>
<li>Macro data in total, per file and per call-site. The macro data contains how
many invocations of a macro were performed, how many AST nodes were
synthesized by the macro and how long it took to perform all the macro
expansions.</li>
</ul>

<p>The profiling logs will be large, so make sure the buffer of your terminal is
big enough so that you can browse through them.</p>

<p>When you&rsquo;ve added all the compile options to the configuration file and
saved it, the next compilation will output a log <a href="/images/bloop-compile-0.txt">similar to this
one</a>. This is the profiling data we&rsquo;re going to dig
into.</p>

<h4 id="the-first-visual">The first visual</h4>

<p>First thing you notice from the data: compilation time has gone up. Don&rsquo;t
worry, you haven&rsquo;t done anything wrong.</p>

<pre><code>#total compile time   : 1 spans, ()46169.708ms
</code></pre>

<p>Compiler plugins add overhead so the increased compilation time is expected.
In particular, the cost of <code>scalac-profiling</code> is high since it instruments
key parts of typer via compiler hooks. Remember that the cost will disappear
as soon as you remove the plugin from the bloop configuration file.</p>

<p>The first thing we need is to get a visual of the implicit searches. To do
that, we&rsquo;re going to create an implicit search flamegraph. Grep for the line
&ldquo;Writing graph to&rdquo; in the logs to find the <code>.flamegraph</code> file containing the
data.</p>

<hr />

<h5 id="learn-to-generate-a-flamegraph">Learn to generate a flamegraph</h5>

<p>To generate a flamegraph, clone
<a href="https://github.com/scalacenter/scalac-profiling">scalacenter/scalac-profiling</a>,
<code>cd</code> into <code>FlameGraph</code> and run the following script in the repository:</p>

<pre><code class="language-bash">./flamegraph.pl \
    --hash --countname=&quot;ns&quot; \
    --color=scala-compilation \
    $PATH_TO_FLAMEGRAPH_DATA &gt; bloop-profile-initial.svg
</code></pre>

<p>You can then visualize it with <code>$BROWSER bloop-profile-initial.svg</code>.</p>

<hr />

<p>After we&rsquo;re all set up, we&rsquo;ll then get an <code>svg</code> file that looks like this:</p>


<figure>
    
        <img src="/images/bloop-profile-0.svg" />
    
    
    <figcaption>
        <h4>Initial flamegraph of implicit search in `frontend`</h4>
        
    </figcaption>
    
</figure>


<p>(The flamegraph is shown as an image but it&rsquo;s an svg. Open the image in a new
tab to be able to hover on every stack, search through the stack entries and
check the compilation times of every box.)</p>

<p>We finally have a visual of all the implicit searches our program is doing,
and how their dependencies look like. But before we keep finding out what the
graph represents, let&rsquo;s take a slight detour and learn about common implicit
and macro usage patterns and in which context they are used.</p>

<p>This background information will help us read the flamegraph.</p>

<h4 id="typeclass-derivation-for-the-win">Typeclass derivation for the win</h4>

<p>Typeclass derivation is a process that synthesizes
<a href="https://en.wikipedia.org/wiki/Type_class">typeclasses</a> from other types. The
process can be manual (you define an <code>Encoder</code> for every node of your GADT)
or automatic (the <code>Encoder</code> derivation happens at compile time, i.e. the
compiler generates the code for you).</p>

<p>There are two families of automatic typeclass derivation:</p>

<ul>
<li>Automatic: to derive a typeclass for a given type <code>T</code>, the compiler will
materialize any typeclass type <code>T</code> needs if it&rsquo;s not in scope.</li>
<li>Semi-automatic: to derive a typeclass for a given type <code>T</code>, all the types <code>T</code>
depends on have to have a derived typeclass in scope.</li>
</ul>

<p>Typeclass derivation is popular in the Scala community. A few libraries (for
example, <code>scalatest</code>) define their own macros to synthesize type classes. The
most common approach, though, is to use Shapeless to guide the type
derivation on the library side, which removes the need for extra macros.</p>

<p>Shapeless is a generic programming library that defines some basic building
blocks (macros) to enable typelevel computations. These computations are
driven by implicit search and happen at compilation time. Shapeless is
popular library for automatic typeclass derivation because it can find out
the generic representation of any <code>sealed trait</code>/<code>case class</code> you have in
your program. So when the implicit search needs an instance that doesn&rsquo;t
exist in the scope, macros materialize it.</p>

<p>The compilation of <code>frontend</code> does automatic typeclass derivation via
<code>case-app</code>, which depends on Shapeless. <code>case-app</code> derives a
<code>caseapp.core.Parser</code> for a GADT defining the commands and parameters that
your command line interface accepts. This derivation relies on the <code>Lazy</code>,
<code>Strict</code>, <code>Tagged</code> and <code>LabelledGeneric</code> macros, as well as other Shapeless
data structures like <code>Coproduct</code> and <code>HList</code>.</p>

<p>These are normal dependencies of any library that uses Shapeless to guide
typeclass derivation.</p>

<h4 id="the-cost-of-implicit-macros">The cost of implicit macros</h4>

<p>Automatic and semi-automatic typeclass derivation use macro definitions
defined as <code>implicit</code> to guide the typeclass derivation at compile-time. For
example, every time you derive an encoder for an <code>HList</code>, say <code>Encoder</code>, you
derive it inductively for every element of its generic representation
(<code>HList</code> or <code>Coproduct</code>).</p>

<p>But how can macro definitions be <code>implicit</code> and what are the consequences of
that?</p>

<pre><code class="language-scala">implicit def foo[T](p: T): Foo[T] = macro fooImpl[T]

// Undefined macro implementation for simplicity
def fooImpl[T: ctx.WeakTypeTag]
  (ctx: blackbox.Context)(p: ctx.Tree): ctx.Tree = ???
</code></pre>

<p>The code above defines an implicit def that synthesizes a type <code>Foo</code> for the
type <code>T</code>. The code generation only depends on <code>p</code> and the type <code>T</code> so there
are no functional dependencies. It is a dummy blackbox macro.</p>

<p>When macros like <code>foo</code> are defined in a library and they are eligible for an
implicit search of type <code>T</code>, the compiler goes through the list of all
candidates based on the priority of implicit search and gets the first
non-ambiguous match. If the match is a macro like <code>foo</code>, the macro is
expanded and the code inlined at the call-site.</p>

<p>This algorithm is correct but problematic for macros. The compiler will
always expand macros that are eligible to the implicit search even if the
resulting trees are thrown away.</p>

<p>On top of that, if several macros are candidates to an implicit search in the
same implicit scope, all of them will be expanded because the compiler needs
to check for ambiguity of implicit instances.</p>

<p>The efficiency of this process worsens when whitebox macros are used. For the
sake of this blog post, let&rsquo;s think of a whitebox macro as a blackbox macro
that can redefine the type of its enclosing definition.</p>

<p>Whitebox macros are powerful and that makes them more expensive than blackbox
macros: <a href="https://github.com/scala/scala/pull/3236">they are typechecked three times by the Scala macro engine</a>.</p>

<p>All kinds of macros eligible for implicit search pose a threat to compile
times and so they need to be used with care.</p>

<h4 id="the-world-of-shapeless">The world of shapeless</h4>

<p>Shapeless defines <strong>28 whitebox macros</strong>. The most common whitebox Shapeless
macros are <code>Generic</code>, <code>Lazy</code>, <code>Nat</code>, <code>Default</code> and polymorphic function
values <code>Poly</code>. These are heavyweight macros that are common in many Scala
projects.</p>

<p>The main problem with these macros is that their use is heavy in automatic
typeclass derivation. When used in that context, it is common that the compiler
repeats the materialization of implicit instances. This is the main source of
inefficiencies.</p>

<p>Travis Brown explains these inefficiences well in a more high-level manner in
<a href="https://meta.plasm.us/slides/scalaworld/#65">this talk about Generic
Derivation</a> at Scalaworld.</p>

<p>Once a macro is triggered because an implicit doesn&rsquo;t exist in the scope of
the call-site, the implicit search needs to materialize all the functional
dependencies (all the implicits that are required for another implicit to be
eligible) together with the implicits in scope.</p>

<p>All these materialized instances <strong>cannot be shared</strong> across different
implicit searches since they don&rsquo;t exist in the call-site. Once the macro is
triggered, the code is expanded and typechecked and nothing can be re-used as
the macro code doesn&rsquo;t have access to the previous expansions.</p>

<h4 id="quick-derivation-example">Quick derivation example</h4>

<pre><code class="language-scala">sealed trait Base
case class Foo(xs: List[String]) extends Base
case class Bar(xs: List[String], i: Int) extends Base

implicitly[Encoder[Foo]]
implicitly[Encoder[Bar]]
</code></pre>

<p>For example, the code above illustrates how an hypothetic <code>Encoder</code> typeclass
would need to materialize <code>List[String]</code> <strong>twice</strong> since its type appears in
both definitions. The second call cannot detect that the first one
synthesizes <code>Encoder[List[String]]</code> because for all purposes there isn&rsquo;t an
implicit instance in scope.</p>

<p>The same happens in nested implicit searches and it worsens as more and more
functional dependencies generated by macros and nested types are used and
required in every step of the inductive process.</p>

<p>Remember that <code>frontend</code> was expanding 44500 macros and how intense was
typechecking? Well, now we have a faint idea why.</p>

<h3 id="the-quest-for-optimization">The quest for optimization</h3>

<p>We now have a clearer idea what we&rsquo;re after. <code>caseapp.core.Parser</code> is just an
standard typeclass that is automatically materialized by Shapeless
recursively.</p>

<p>The profiling data reveals us that the majority of the time is spent in
macro expansion and implicit searches, so it&rsquo;s likely we should see some of
the repeated materialized instances we discussed about in the previous
section.</p>

<p>Let&rsquo;s look at the profiling data again.</p>

<p>&ldquo;Implicit searches by position&rdquo; and &ldquo;Macro data per file&rdquo; tell us that almost
all of the work happens in a file called <code>CliParsers</code>.</p>

<pre><code class="language-scala">
object CliParsers {
  // Stubs to simplify reading the code
  implicit val inputStreamRead: ArgParser[InputStream] = ???
  implicit val printStreamRead: ArgParser[PrintStream] = ???
  implicit val pathParser: ArgParser[Path] = ???

  implicit val completionFormatRead: ArgParser[Format] = ???
  implicit val propParser: ArgParser[PrettyProperties] = ???

  import caseapp.core.{Messages, Parser}
  val BaseMessages: Messages[DefaultBaseCommand] =
    Messages[DefaultBaseCommand]
  val OptionsParser: Parser[CliOptions] =
    Parser.apply[CliOptions]

  import caseapp.core.{CommandsMessages, CommandParser}
  val CommandsMessages: CommandsMessages[RawCommand] =
    CommandsMessages[RawCommand]
  val CommandsParser: CommandParser[RawCommand] =
    CommandParser.apply[RawCommand]
}
</code></pre>

<p>The file defines specific parsers for data structures that <code>frontend</code>
defines, creates an instance of <code>caseapp.core.Messages</code>, a parser for cli
options, and then two instances of <code>CommandsMessages</code> and <code>CommandsParser</code>.</p>

<p>The two lines that define <code>CommandsMessages</code> and <code>CommandsParser</code> are the
ones that dominate the compilation time.</p>

<p><code>CommandsParser</code> is creating a parser for all the commands defined in the
<code>RawCommand</code> GADT, which you can find in <a href="https://github.com/scalacenter/bloop/blob/v1.0.0-M10/frontend/src/main/scala/bloop/cli/Commands.scala#L28">this source
file</a>.
<code>RawCommand</code> has eight subclasses (commands) that specify the inputs required
for every CLI invocation. Each of this commands defines a <code>@Recurse</code>
field that allows Shapeless to reuse the parser for <code>CliOptions</code>.
<code>CliOptions</code> in turn requires the parser of <code>CommonOptions</code> in the same
fashion. Materializing this parser takes almost 14 seconds.</p>

<p><code>CommandsMessages</code> does a similar thing but instead of materializing a parser
it materializes a class with a map of all the commands and information about
the parameters (fields) it takes. The materialization of <code>Messages</code> takes
around 13 seconds.</p>

<p>Let&rsquo;s come back to the flamegraph. We&rsquo;re now ready to continue our
exploration.</p>

<h4 id="reading-the-implicit-search-flamegraph">Reading the implicit search flamegraph</h4>


<figure>
    
        <img src="/images/bloop-profile-0.svg" />
    
    
    <figcaption>
        <h4>Initial flamegraph of implicit search in `frontend`</h4>
        
    </figcaption>
    
</figure>


<p>The flamegraph has three colors. Every color has a meaning.</p>

<ol>
<li>Green: a successful implicit search whose result didn&rsquo;t come from a macro (the normal case).</li>
<li>Blue (aqua): a successful implicit search whose result came from a macro.</li>
<li>Red: a failed implicit search that triggered at least one macro.</li>
</ol>

<p>Every implicit search in the graph has some metadata at the end of the title.
Depending on the color, we can find:</p>

<ol>
<li>Implicit search id: a number to identify an implicit search and inspect
its result tree via <code>-P:scalac-profiling:print-search-result:$SEARCH_ID</code>.</li>
<li>The number of macro expansions triggered by an implicit search. This number
only covers the direct macro expansions (not the transitive ones).</li>
<li>If the result tree comes from a macro, the macro location that expanded it.</li>
</ol>

<p>Example:</p>

<pre><code>shapeless.Strict[caseapp.core.Parser[bloop.cli.Commands.Run]] (id 12121) (expanded macros 3) (tree from `shapeless.LazyMacrosRef.mkStrictImpl`)  (417,117 ns, 3.28%)
</code></pre>

<p>On every stack trace, you have also the information about the timing. The
unit of time is nanoseconds. So one million ns is one second. We use
nanoseconds because flamegraphs cannot display decimal values and we don&rsquo;t
want to lose time precision.</p>

<p>Beware that an implicit search may not appear in the flamegraph even if it&rsquo;s
performed by <code>scalac</code>. There could be implicit searches that are so fast to
do that they take less than 0ns. Flamegraphs do not show entries whose value
is under 0.</p>

<p>We&rsquo;re not going to use all of this information in the blog post, but it may
turn handy whenever you research on your own. Check the rest of the supported
compiler plugin flags <a href="https://github.com/scalacenter/scalac-profiling/blob/master/plugin/src/main/scala/ch/epfl/scala/ProfilingPlugin.scala#L33-L40">in the code</a>.</p>

<p>After this short intro, let&rsquo;s delve into the data. The first thing that
strucks me is how similar all the towers of implicits look (both in shape and
duration). If we hover over all the chunks, the repetition will be obvious;
most bite-sized chunks materialize either <code>Parser[CommonOptions]</code> or
<code>Parser[CliOptions]</code>, depending at the height of the implicit branch we look
at.</p>

<p>This makes sense. After all, we&rsquo;re not caching these implicits in the call
sites. Let&rsquo;s cache them before the materialization of <code>CommandsMessages</code> and
<code>CommandsParser</code>.</p>

<pre><code class="language-scala">implicit val coParser: Parser.Aux[CommonOptions, _] =
  Parser.generic
implicit val cliParser: Parser.Aux[CliOptions, _] =
  Parser.generic
</code></pre>

<p>The code above calls the materialization entrypoints from <code>caseapp.Parser</code>
directly. Type inference and implicit search will figure out the type
parameters that <code>Parser.generic</code> needs from the return type we specify
explicitly in the cached implicits.</p>

<hr />

<p>A word of caution when caching implicits: make sure the rhs of the implicit
definition doesn&rsquo;t depend on the implicit you&rsquo;re caching.</p>

<p>It is common that <code>scalac</code> detects <code>coParser</code> as the candidate for the
implicit search on its rhs. This creates a recursive call that causes a null
pointer exception at runtime. We can reproduce the issue if we redefine
<code>coParser</code> as <code>implicitly[Parser[CommonOptions]]</code> or
<code>the[Parser[CommonOptions]]</code>.</p>

<hr />

<p>Great! Well, let&rsquo;s check the compile time and flamegraphs now.</p>

<pre><code>#total compile time  : 1 spans, ()19060.196ms
  typer              : 1 spans, ()13625.005ms (71.5%)
</code></pre>


<figure>
    
        <img src="/images/bloop-profile-1.svg" />
    
    
    <figcaption>
        <h4>Flamegraph after cached implicits</h4>
        
    </figcaption>
    
</figure>


<p>The compile time is 2.5x faster. Not bad for a two line change. The duration
of implicit search accounts for 13 seconds, roughly ~95% of typer.</p>

<p>The flamegraph has slim down and doesn&rsquo;t contain the successful implicit
searches for <code>Parser[CommonOptions]</code> and <code>Parser[CliOptions]</code>. However, there
seems to be quite a few of failed implicit searches that trigger unnecessary
macro expansions that are afterwards discarded because their type doesn&rsquo;t
match the predicate type of the implicit search.</p>

<pre><code>caseapp.core.Parser[bloop.cli.CliOptions]{type D = HD} (expanded macros 0)   (278,828 ns, 2.19%)
caseapp.core.Parser[bloop.cli.CommonOptions]{type D = HD} (expanded macros 0)   (189,414 ns, 1.49%)
</code></pre>

<p>It looks like the implicit search doesn&rsquo;t immediately reuse our cached
parsers for <code>CommonOptions</code> and <code>CliOptions</code> and first tries to pass in a
explicit refinement type <code>D</code> that fails the search. The error seems to happen
when finding an implicit for <code>HListParser</code> (which takes type parameters
<a href="https://github.com/alexarchambault/case-app/blob/v1.2.0/core/shared/src/main/scala/caseapp/core/Parser.scala#L77-L84">inferred from its other functional
dependencies</a>.</p>

<p>Let&rsquo;s further debug this with <code>-Xlog-implicits</code> (by adding it to the scalac
options of the bloop configuration file).</p>

<p>(This is a good moment to try to minimize the problem. <code>-Xlog-implicits</code> will
log a lot of failed searches and we want to be able to see through the noise.
I did minimise it the issue easily by just asking for
<code>implicitly[Parser[CliOptions]]</code>.)</p>

<p>Among all the logs, the one type that calls my attention is the following:</p>

<pre><code>/data/rw/code/scala/loop/frontend/src/main/scala/bloop/cli/CliParsers.scala:48:37: shapeless.this.Generic.materialize is not a valid implicit value for shapeless.Generic.Aux[bloop.cli.CommonOptions,V] because:
type parameters weren't correctly instantiated outside of the implicit tree: inferred type arguments [String :: java.io.PrintStream :: java.io.InputStream :: java.io.PrintStream :: java.io.PrintStream :: java.io.PrintStream :: bloop.cli.CommonOptions.PrettyProperties :: Int :: shapeless.HNil,Nothing] do not conform to method materializeCoproduct's type parameter bounds [V &lt;: shapeless.Coproduct,R &lt;: shapeless.Coproduct]
    caseapp.core.CommandParser.apply[Commands.RawCommand]
                                    ^
</code></pre>

<p>Interesting. The compiler infers <code>R</code> to be <code>Nothing</code>, which of course cannot
be a <code>Coproduct</code>, but that doesn&rsquo;t prevent the macro in
<code>materializeCoproduct</code> to materialize and suck up some of our compile times.
After all, the implicit search needs to have the exact return type of the
macro.</p>

<p><code>Generic</code> is required by <code>case-app</code> via <code>LabelledGeneric</code>, which is required
by <code>HListParser</code>. However, why is <code>materializeCoproduct</code> eligible in this
context if all we want is to derive parsers for all the products of <code>Command</code>
(e.g. all the subclasses that extend the <code>Command</code> GADT)?</p>

<p>It seems this is bringing us to uncharted territory. We now need to
investigate what the <code>Generic</code> macro is doing in the Shapeless codebase.</p>

<h4 id="a-tour-through-shapeless-s-generic">A tour through Shapeless&rsquo;s <code>Generic</code></h4>

<p><code>Generic</code> is a macro that will derive the generic representation of a given
product, a type that aggregates other types. A <code>case class Foo(i: Int, s:
String)</code> aggregates <code>Int</code> and <code>String</code> types, whereas a <code>sealed trait Bar</code> is
either of all its subclasses.</p>

<p>The source code of <code>Generic</code> has two implicit candidates that materialize the
instance depending if the candidate type is a <code>Product</code> or a <code>Coproduct</code>:
<a href="https://github.com/milessabin/shapeless/blob/a42cd4c1c99e4a7be36e0239d3ee944a6355e321/core/src/main/scala/shapeless/generic.scala#L218-L230"><code>materializeProduct</code></a>
and
<a href="Xhttps://github.com/milessabin/shapeless/blob/a42cd4c1c99e4a7be36e0239d3ee944a6355e321/core/src/main/scala/shapeless/generic.scala#L232-L245"><code>materializeCoproduct</code></a>.</p>

<p>The problem of incorrect instantiated type arguments we saw before seems
specific to the way the compiler carries out the implicit search. Fixing it
requires most likely changes to the implicit search algorithm, as <a href="https://github.com/scala/bug/issues/10528">a similar
scala/bug did</a>. I tried porting
these changes to 2.12.x and use <code>-Xsource:2.13</code> but the failed macro
expansions didn&rsquo;t go away.</p>

<p>So we need to find a way to fix this in userspace if we want to make the logs
disappear. The root of the issue is that both <code>materializeProduct</code> and
<code>materializeCoproduct</code> are candidates of the implicit search and both are
tried (<em>for some reason</em>, both are considered eligible even though
<code>materializeCoprodut</code> shouldn&rsquo;t and the compiler needs tro ty both to make
sure there are no ambiguous implicits in the same scope).</p>

<p>Let&rsquo;s try a trick. Let&rsquo;s move the definition of <code>materializeCoproduct</code> to a
trait of low priority implicits that the <code>Generic</code> companion extends. This
way, <code>materializeProduct</code> (the most common materializer) will always be the
first one to be tried and only if that fails the implicit search will try
<code>materializeCoproduct</code> in the lower priority scope that is any super class of
the <code>Generic</code> companion class.
After <a href="https://github.com/jvican/shapeless/commit/9a6d70cbda92849ff2a9b3d99f2aa4d5d82bf21f">making the
change</a>
in the Shapeless codebase, we <code>coreJVM/package</code> in the shapeless build and
replace the jar of shapeless 2.3.3 in the classpath by the one we just
created with <code>package</code>. We also remove <code>-Xlog-implicits</code> and compile.</p>

<pre><code>#total compile time  : 1 spans, ()16869.585ms
  typer              : 1 spans, ()13011.067ms (77.1%)
#implicit searches          : 13515
  #plausibly compatible     : 15415 (114.1%)
  #matching                 : 15415 (114.1%)
  #typed                    : 15381 (113.8%)
  #found                    : 8082 (59.8%)
  #implicit improves tests  : 3673 (27.2%)
  #implicit improves cached : 2614 (19.3%)
  #implicit inscope hits    : 348 (2.6%)
  #implicit oftype hits     : 7400 (54.8%)
  from macros               : 12851 (95.1%)
time spent in implicits   : 13515 spans, ()12409.099ms (95.4%)
  successful in scope     : 348 spans, ()78.224ms (0.6%)
  failed in scope         : 13167 spans, ()1363.491ms (10.5%)
  successful of type      : 7400 spans, ()12287.668ms (94.4%)
  failed of type          : 5767 spans, ()8322.049ms (64.0%)
  assembling parts        : 8033 spans, ()237.456ms (1.8%)
  matchesPT               : 79854 spans, ()566.231ms (4.4%)
time spent in macroExpand : 17175 spans, ()11974.695ms (92.0%)
</code></pre>


<figure>
    
        <img src="/images/bloop-profile-2.svg" />
    
    
    <figcaption>
        <h4>Implicit flamegraph after shapeless change</h4>
        
    </figcaption>
    
</figure>


<p>The change had a mild positive effect &ndash; we gained two seconds. This change
seems to have removed the log we saw before and some of the failed implicit
searches from the flamegraph, but most of the other ones still persist.</p>

<p>What is really going on? Our change fixed the unnecessary expansion for
<code>Generic</code>, but there seems to be a more fundamental issue at play.</p>

<h4 id="strict-lazy-don-t-like-the-aux-pattern">Strict/Lazy don&rsquo;t like the aux pattern</h4>

<p>It took me a while to find out what was happening, though I couldn&rsquo;t come up
with a fix in the compiler (where I think the real issue is &ndash; though it&rsquo;s
still to be determined). However, I did come up with a fix in the library
side.</p>

<hr />

<p>After looking at the new output of <code>-Xlog-implicits</code>, I realized that the
compiler must find a mismatch in the refinement types that are inferred
previously to the search and materialized after the expansion.</p>

<p>The <a href="https://github.com/milessabin/shapeless/blob/a42cd4c1c99e4a7be36e0239d3ee944a6355e321/core/src/main/scala/shapeless/generic.scala#L120-L148"><code>Aux</code>
pattern</a>,
a common technique used when declaring typeclasses, relies heavily on
refinement types and all the failed implicit searches seem to be related in
some way or another to the aux pattern of either <code>HListParser</code> or <code>Strict</code>.</p>

<p>We can have a look at the definition of <code>Parser</code> again, which requires the
materialization of <code>HListParser</code>. I intuited that the <code>Strict</code> macro may be
doing something weird under the hood and causing the type mismatch.</p>

<p>I expanded and pretty-printed some of the implicit logs I found:</p>

<pre><code class="language-scala">shapeless.Strict[
  caseapp.core.HListParser.Aux[
    shapeless.labelled.FieldType[Symbol with shapeless.tag.Tagged[String(&quot;workingDirectory&quot;)],String] :: java.io.PrintStream with shapeless.labelled.KeyTag[Symbol with shapeless.tag.Tagged[String(&quot;out&quot;)],java.io.PrintStream] :: java.io.InputStream with shapeless.labelled.KeyTag[Symbol with shapeless.tag.Tagged[String(&quot;in&quot;)],java.io.InputStream] :: java.io.PrintStream with shapeless.labelled.KeyTag[Symbol with shapeless.tag.Tagged[String(&quot;err&quot;)],java.io.PrintStream] :: java.io.PrintStream with shapeless.labelled.KeyTag[Symbol with shapeless.tag.Tagged[String(&quot;ngout&quot;)],java.io.PrintStream] :: java.io.PrintStream with shapeless.labelled.KeyTag[Symbol with shapeless.tag.Tagged[String(&quot;ngerr&quot;)],java.io.PrintStream] :: shapeless.HNil,
    Option[String] :: Option[java.io.PrintStream] :: Option[java.io.InputStream] :: Option[java.io.PrintStream] :: Option[java.io.PrintStream] :: Option[java.io.PrintStream] :: shapeless.HNil,
    List[caseapp.Name] :: scala.collection.immutable.Nil.type :: scala.collection.immutable.Nil.type :: scala.collection.immutable.Nil.type :: scala.collection.immutable.Nil.type :: scala.collection.immutable.Nil.type :: shapeless.HNil,
    Option[caseapp.ValueDescription] :: None.type :: None.type :: None.type :: None.type :: None.type :: shapeless.HNil,
    Option[caseapp.HelpMessage] :: None.type :: None.type :: None.type :: None.type :: None.type :: shapeless.HNil,
    Option[caseapp.Hidden] :: Some[caseapp.Hidden] :: Some[caseapp.Hidden] :: Some[caseapp.Hidden] :: Some[caseapp.Hidden] :: Some[caseapp.Hidden] :: shapeless.HNil,
    None.type :: None.type :: None.type :: None.type :: None.type :: None.type :: shapeless.HNil,
    Option[String] :: this.P
  ]
]

does not match expected type

shapeless.Strict[
  caseapp.core.HListParser.Aux[
    shapeless.labelled.FieldType[Symbol @@ String(&quot;workingDirectory&quot;),String] :: shapeless.labelled.FieldType[Symbol @@ String(&quot;out&quot;),java.io.PrintStream] :: shapeless.labelled.FieldType[Symbol @@ String(&quot;in&quot;),java.io.InputStream] :: shapeless.labelled.FieldType[Symbol @@ String(&quot;err&quot;),java.io.PrintStream] :: shapeless.labelled.FieldType[Symbol @@ String(&quot;ngout&quot;),java.io.PrintStream] :: shapeless.labelled.FieldType[Symbol @@ String(&quot;ngerr&quot;),java.io.PrintStream] :: shapeless.ops.hlist.ZipWithKeys.hnilZipWithKeys.Out,
    Option[String] :: Option[java.io.PrintStream] :: Option[java.io.InputStream] :: Option[java.io.PrintStream] :: Option[java.io.PrintStream] :: Option[java.io.PrintStream] :: shapeless.HNil,
    scala.collection.immutable.Nil.type :: scala.collection.immutable.Nil.type :: scala.collection.immutable.Nil.type :: scala.collection.immutable.Nil.type :: scala.collection.immutable.Nil.type :: scala.collection.immutable.Nil.type :: shapeless.HNil,
    None.type :: None.type :: None.type :: None.type :: None.type :: None.type :: shapeless.HNil,
    None.type :: None.type :: None.type :: None.type :: None.type :: None.type :: shapeless.HNil,
    Some[caseapp.Hidden] :: Some[caseapp.Hidden] :: Some[caseapp.Hidden] :: Some[caseapp.Hidden] :: Some[caseapp.Hidden] :: Some[caseapp.Hidden] :: shapeless.HNil,
    None.type :: None.type :: None.type :: None.type :: None.type :: None.type :: shapeless.HNil,
    HD
  ]
]
</code></pre>

<p>And inspect the generated code by the macro expansion by using
<code>-P:scalac-profiling:print-search-result:_</code> and
<code>-Ymacro-debug-lite</code>/<code>-Ymacro-debug-verbose</code> (which dumps all macro related
logs). That extra inspection gave me some hints.</p>

<p>The issue seems to be in the refinement of <code>HListParser</code>. In the previous log the last type parameter of <code>HListParser.Aux</code> (the refinement type) was <code>HD</code>, an abstract type used
<a href="https://github.com/alexarchambault/case-app/blob/v1.2.0/core/shared/src/main/scala/caseapp/core/HListParser.scala#L131-L159">here</a>,
and the returned refinement type from the macro was <code>Option[String] ::
this.P</code>.</p>

<p>We can try to debug and expand all type parameters, see what we get and
continue the exploration from there. But whenever we find such a misterious
open-ended error, it&rsquo;s difficult to pinpoint what the real problem and fix
should be.</p>

<p>Myself, I had a gut feeling that the <code>Strict</code> macro was interacting weirdly
with the aux pattern and followed that hint. The way we can test this hypothesis
is by going to <a href="https://github.com/alexarchambault/case-app/blob/v1.2.0/core/shared/src/main/scala/caseapp/core/Parser.scala#L84">the definition of
<code>Parser</code></a>
where we remove the <code>Strict</code> wrapping <code>HListParser</code>, <code>++2.12.6
coreJVM/package</code> in the sbt build and replace the new jar by the classpath
entry for case-app core we&rsquo;re using in <code>frontend.json</code>. Afterwards we compile.</p>

<p>This change may cause errors since the use of <code>Strict</code> and <code>Lazy</code> disable the
implicit divergence checks of the compiler, which can give false positives
when working with Shapeless data structures (short story).</p>

<pre><code>/data/rw/code/scala/loop/frontend/src/main/scala/bloop/Bloop.scala:22:22:could not find implicit value for parameter parser: caseapp.Parser[bloop.cli.CliOptions]
object Bloop extends CaseApp[CliOptions] {
                     ^
/data/rw/code/scala/loop/frontend/src/main/scala/bloop/Bloop.scala:22:22:not enough arguments for constructor CaseApp: (implicit parser: caseapp.Parser[bloop.cli.CliOptions], implicit messages: caseapp.core.Messages[bloop.cli.CliOptions]) caseapp.CaseApp[bloop.cli.CliOptions].
Unspecified value parameters parser, messages.
object Bloop extends CaseApp[CliOptions] {
                     ^
</code></pre>

<p>The error can be mitigated by importing <code>coParser</code> and <code>cliParser</code> from
<code>CliParsers</code> in the <code>Bloop.scala</code> source file. But doing so would change our
baseline (because we&rsquo;re caching <code>Parser[CliOptions]</code> in another call-site
that isn&rsquo;t our initial <code>CliParsers</code>). So let&rsquo;s remove the new case-app
classpath entry, compile with the old case-app, and then compile again with
the changed version.</p>

<pre><code>#total compile time  : 1 spans, ()15972.609ms
  typer              : 1 spans, ()11360.512ms (71.1%)
</code></pre>


<figure>
    
        <img src="/images/bloop-profile-3.svg" />
    
    
    <figcaption>
        <h4>New flamegraph baseline</h4>
        
    </figcaption>
    
</figure>


<p>The new caching only shaves around ~600ms of compile times. Let&rsquo;s check
compiling with our new case-app now.</p>

<pre><code>#total compile time  : 1 spans, ()7432.332ms
  typer              : 1 spans, ()5074.836ms (68.3%)
</code></pre>


<figure>
    
        <img src="/images/bloop-profile-4.svg" />
    
    
    <figcaption>
        <h4>Flamegraph after case-app change</h4>
        
    </figcaption>
    
</figure>


<p>Bingo! Most of the time-consuming failed implicit searches are gone and
compilation time has halved. Our hypothesis is confirmed: the <code>Strict</code> macro
is doing something suspicious.</p>

<p>We could try to find out what that is, but that would require us to
investigate how the <code>Strict</code> macro works and spot why it doesn&rsquo;t behave
correctly.</p>

<p>We&rsquo;re short of time, so our best call is to file a ticket and let others more
experienced with the codebase have a look at it. If we&rsquo;re lucky, someone will
fix this issue upstream soon and we&rsquo;ll benefit from this speed up when we
upgrade.</p>

<h4 id="removing-more-repetition">Removing more repetition</h4>

<p>There are still too many repeated tower of implicits in our flamegraph.
<code>CommandsParser</code> and <code>CommandsMessages</code> are deriving <code>Parser</code>s for every type
in our <code>Command</code> GADT twice. Let&rsquo;s cache those too.</p>

<pre><code class="language-scala">implicit val autocompleteParser: Parser.Aux[Commands.Autocomplete, _] = Parser.generic
implicit val aboutParser: Parser.Aux[Commands.About, _] = Parser.generic
implicit val bspParser: Parser.Aux[Commands.Bsp, _] = Parser.generic
implicit val cleanParser: Parser.Aux[Commands.Clean, _] = Parser.generic
implicit val compileParser: Parser.Aux[Commands.Compile, _] = Parser.generic
implicit val configureParser: Parser.Aux[Commands.Configure, _] = Parser.generic
implicit val helpParser: Parser.Aux[Commands.Help, _] = Parser.generic
implicit val projectsParser: Parser.Aux[Commands.Projects, _] = Parser.generic
implicit val runParser: Parser.Aux[Commands.Run, _] = Parser.generic
implicit val testParser: Parser.Aux[Commands.Test, _] = Parser.generic
</code></pre>

<pre><code>#total compile time  : 1 spans, ()10154.603ms
  typer              : 1 spans, ()7925.156ms (78.0%)
</code></pre>


<figure>
    
        <img src="/images/bloop-profile-5.svg" />
    
    
    <figcaption>
        <h4>New flamegraph baseline</h4>
        
    </figcaption>
    
</figure>


<p>We&rsquo;re in the right direction, but there doesn&rsquo;t seem to be any
straightforward way of decreasing that compilation time anymore.</p>

<p>The flamegraph may not make obvious how many repeated expansions are
happening in every branch, so let&rsquo;s have a look at the data emitted by
<code>-P:scalac-profiling:show-profiles</code>.</p>

<p>The &ldquo;Macro expansions by type&rdquo; and &ldquo;Implicit searches by type&rdquo; tells us
how many repeated macros and implicit searches we have per type.</p>

<p>An example of the most important ones from &ldquo;Implicit searches by type&rdquo; is.</p>

<pre><code>  &quot;caseapp.util.Implicit[caseapp.core.Default[String] :: shapeless.HNil]&quot; -&gt; 20,
  &quot;caseapp.core.Default[String] :: shapeless.HNil&quot; -&gt; 20,
  &quot;caseapp.util.Implicit[Some[caseapp.core.Default[String]] :+: None.type :+: shapeless.CNil]&quot; -&gt; 20,
  &quot;caseapp.core.Default[String]&quot; -&gt; 20,
  &quot;Some[caseapp.core.Default[String]] :+: None.type :+: shapeless.CNil&quot; -&gt; 20,
  &quot;caseapp.util.Implicit[Option[caseapp.core.Default[String]]]&quot; -&gt; 20,
  &quot;caseapp.core.ArgParser[String]&quot; -&gt; 20,
  &quot;caseapp.util.Implicit[Some[caseapp.core.Default[String]]]&quot; -&gt; 20,
  &quot;Option[caseapp.core.Default[String]]&quot; -&gt; 20,
  &quot;shapeless.HNil&quot; -&gt; 21,
  &quot;Some[caseapp.core.Default[Boolean]] :+: None.type :+: shapeless.CNil&quot; -&gt; 35,
  &quot;caseapp.core.Default[Boolean]&quot; -&gt; 35,
  &quot;caseapp.util.Implicit[Some[caseapp.core.Default[Boolean]] :+: None.type :+: shapeless.CNil]&quot; -&gt; 35,
  &quot;caseapp.util.Implicit[caseapp.core.Default[Boolean]]&quot; -&gt; 35,
  &quot;shapeless.Strict[caseapp.core.ArgParser[Boolean]]&quot; -&gt; 35,
  &quot;caseapp.core.Default[Boolean] :: shapeless.HNil&quot; -&gt; 35,
  &quot;caseapp.util.Implicit[Some[caseapp.core.Default[Boolean]]]&quot; -&gt; 35,
  &quot;caseapp.util.Implicit[Option[caseapp.core.Default[Boolean]]]&quot; -&gt; 35,
  &quot;Some[caseapp.core.Default[Boolean]]&quot; -&gt; 35,
  &quot;Option[caseapp.core.Default[Boolean]]&quot; -&gt; 35,
  &quot;caseapp.util.Implicit[caseapp.core.Default[Boolean] :: shapeless.HNil]&quot; -&gt; 35,
  &quot;caseapp.util.Implicit[Option[caseapp.core.Default[java.io.PrintStream]]]&quot; -&gt; 56,
  &quot;caseapp.util.Implicit[Some[caseapp.core.Default[java.io.PrintStream]] :+: None.type :+: shapeless.CNil]&quot; -&gt; 56,
  &quot;Some[caseapp.core.Default[java.io.PrintStream]] :+: None.type :+: shapeless.CNil&quot; -&gt; 56,
  &quot;shapeless.Strict[caseapp.core.ArgParser[java.io.PrintStream]]&quot; -&gt; 56,
  &quot;Option[caseapp.core.Default[java.io.PrintStream]]&quot; -&gt; 56,
  &quot;caseapp.core.Default[java.io.PrintStream]&quot; -&gt; 56,
  &quot;caseapp.util.Implicit[caseapp.core.Default[java.io.PrintStream]]&quot; -&gt; 56,
  &quot;Some[caseapp.core.Default[java.io.PrintStream]]&quot; -&gt; 56,
  &quot;caseapp.util.Implicit[caseapp.core.Default[java.io.PrintStream] :: shapeless.HNil]&quot; -&gt; 56,
  &quot;caseapp.core.Default[java.io.PrintStream] :: shapeless.HNil&quot; -&gt; 56,
  &quot;caseapp.util.Implicit[Some[caseapp.core.Default[java.io.PrintStream]]]&quot; -&gt; 56,
  &quot;None.type&quot; -&gt; 153,
  &quot;caseapp.util.Implicit[None.type]&quot; -&gt; 153,
  &quot;caseapp.util.Implicit[None.type :+: shapeless.CNil]&quot; -&gt; 153,
  &quot;caseapp.util.Implicit[shapeless.HNil]&quot; -&gt; 185
</code></pre>

<p>Let&rsquo;s cache some more implicits from here, especially the ones we intuit are
most expensive.</p>

<pre><code class="language-scala">import shapeless.{HNil, CNil, :+:, ::, Coproduct}
implicit val implicitHNil: Implicit[HNil] = Implicit.hnil
implicit val implicitNone: Implicit[None.type] = Implicit.instance(None)
implicit val implicitNoneCnil: Implicit[None.type :+: CNil] =
  Implicit.instance(Coproduct(None))

implicit val implicitOptionDefaultString: Implicit[Option[Default[String]]] =
  Implicit.instance(Some(caseapp.core.Defaults.string))

implicit val implicitOptionDefaultInt: Implicit[Option[Default[Int]]] =
  Implicit.instance(Some(caseapp.core.Defaults.int))

implicit val implicitOptionDefaultBoolean: Implicit[Option[Default[Boolean]]] =
  Implicit.instance(Some(caseapp.core.Defaults.boolean))

implicit val implicitDefaultBoolean: Implicit[Default[Boolean]] =
  Implicit.instance(caseapp.core.Defaults.boolean)

implicit val implicitOptionDefaultOptionPath: Implicit[Option[Default[Option[Path]]]] =
  Implicit.instance(None)

implicit val implicitOptionDefaultPrintStream: Implicit[Option[Default[PrintStream]]] =
  Implicit.instance(Some(Default.instance[PrintStream](System.out)))

implicit val implicitOptionDefaultInputStream: Implicit[Option[Default[InputStream]]] =
  Implicit.instance(Some(Default.instance[InputStream](System.in)))
implicit val labelledGenericCommonOptions: LabelledGeneric.Aux[CommonOptions, _] =
  LabelledGeneric.materializeProduct
implicit val labelledGenericCliOptions: LabelledGeneric.Aux[CliOptions, _] =
  LabelledGeneric.materializeProduct
</code></pre>

<p>And now let&rsquo;s check the compilation time.</p>

<pre><code>#total compile time  : 1 spans, ()7285.771ms
  typer              : 1 spans, ()5435.895ms (74.6%)
</code></pre>


<figure>
    
        <img src="/images/bloop-profile-6.svg" />
    
    
    <figcaption>
        <h4>Flamegraph after all cached implicits</h4>
        
    </figcaption>
    
</figure>


<p>Great, that reduced compile times by 3 more seconds. You can continue the
same strategy over and over. This is where we stop; we have already cached the
most expensive implicits, so other additions won&rsquo;t have such a big impact.</p>

<p>You get the general idea of the process: read the profiles and optimize
according to what the data shows and your understanding of the codebase is.</p>

<p>We only have one left assignment: removing all those failed implicit searches
in our flamegraph. We saw that wrapping the implicit in <code>Strict</code> was
problematic, can we do something about it in our end instead of waiting for a
fix upstream?</p>

<p>The answer is yes. <code>Strict</code> or <code>Lazy</code> are only required when:</p>

<ol>
<li>We have recursive GADTs.</li>
<li>We use an automatic typeclass derivation scheme that increases the number
of type parameters to be determined by implicit search and thus &ldquo;diverge&rdquo; the
search.</li>
</ol>

<p>Good, we don&rsquo;t have a recursive GADT (and it&rsquo;s unlikely you will in a CLI
application). But we do have an automatic typeclass derivation process that
meets the previous criteria. We experienced the implicit search failure
before when we removed the <code>Strict</code> typeclass from <code>case-app</code> and
<code>Bloop.scala</code> failed to compile.</p>

<p>Such automatic typeclass derivation, though, doesn&rsquo;t diverge after we cached
the implicits! The divergence only happens when we derive typeclasses for
types transitively. For example, deriving <code>CliOptions</code> because it&rsquo;s the type
of a parameter in a command.</p>

<p>Once we cached these intermediary derivations, we can safely remove the
<code>Strict</code>s that cause the most problematic derivations. In particular, the
change we did before and another use of <code>Strict</code> in the
<code>HListParser.hconsRecursive</code>.</p>

<p>The resulting diff in <code>case-app</code> is
<a href="https://github.com/jvican/case-app/commit/148ffb0a20226a6224ab53f87a8f7411036cdd3f">here</a>.</p>

<p>It&rsquo;s worth noting what we&rsquo;re doing here explicitly: we&rsquo;re trading compile
times by ergonomics. Whenever we add a parameter that doesn&rsquo;t have a cached
<code>Parser</code> for it in <code>CliParser</code>, the implicit search will fail with a <code>&quot;Not
found implicit instance&quot;</code> error.</p>

<p>This is a judgement call. Personally, I prefer having faster compile times
than ergonomics, and even more so if the part of the code (the cli) doesn&rsquo;t
change often as it is the case. Let&rsquo;s try out the new change!</p>

<pre><code>#total compile time  : 1 spans, ()4511.197ms
  typer              : 1 spans, ()2887.031ms (64.0%)
</code></pre>


<figure>
    
        <img src="/images/bloop-profile-7.svg" />
    
    
    <figcaption>
        <h4>Flamegraph after caching &#43; case-app changes</h4>
        
    </figcaption>
    
</figure>


<p>Great! We now have a compile time under 5 seconds for an application that
still uses a powerful derivation mechanism, it&rsquo;s easy to maintain and it&rsquo;s
over 6000 LOC.</p>

<p>In the flamegraph, we observe that we have removed the most expensive failed
implicit searches, while some negligible searches remain. We can live with
those.</p>

<p>The duration of the typechecker is back to normal levels: 64%, a reasonable
value for the codebase we&rsquo;re working on. We now need to remove the
instrumentation overhead to see what&rsquo;s the final speedup we get.</p>

<h4 id="getting-the-final-results">Getting the final results</h4>

<p>Let&rsquo;s remove the <code>scalac-profiling</code> plugin and all its flags from
<code>frontend.json</code>. Run compilation two or three times to get stable results.</p>

<pre><code>*** Cumulative timers for phases
#total compile time           : 1 spans, ()4098.49ms
  parser                      : 1 spans, ()18.775ms (0.5%)
  namer                       : 1 spans, ()12.408ms (0.3%)
  packageobjects              : 1 spans, ()0.074ms (0.0%)
  typer                       : 1 spans, ()2612.532ms (63.7%)
  patmat                      : 1 spans, ()286.802ms (7.0%)
  superaccessors              : 1 spans, ()12.026ms (0.3%)
  extmethods                  : 1 spans, ()3.201ms (0.1%)
  pickler                     : 1 spans, ()6.389ms (0.2%)
  xsbt-api                    : 1 spans, ()75.191ms (1.8%)
  xsbt-dependency             : 1 spans, ()54.559ms (1.3%)
  refchecks                   : 1 spans, ()122.441ms (3.0%)
  uncurry                     : 1 spans, ()130.194ms (3.2%)
  fields                      : 1 spans, ()57.397ms (1.4%)
  tailcalls                   : 1 spans, ()13.512ms (0.3%)
  specialize                  : 1 spans, ()105.903ms (2.6%)
  explicitouter               : 1 spans, ()26.837ms (0.7%)
  erasure                     : 1 spans, ()193.214ms (4.7%)
  posterasure                 : 1 spans, ()16.83ms (0.4%)
  lambdalift                  : 1 spans, ()41.906ms (1.0%)
  constructors                : 1 spans, ()11.108ms (0.3%)
  flatten                     : 1 spans, ()14.379ms (0.4%)
  mixin                       : 1 spans, ()15.936ms (0.4%)
  cleanup                     : 1 spans, ()11.516ms (0.3%)
  delambdafy                  : 1 spans, ()26.534ms (0.6%)
  jvm                         : 1 spans, ()224.115ms (5.5%)
  xsbt-analyzer               : 1 spans, ()1.376ms (0.0%)
Done compiling.
</code></pre>

<p>It is safe to say it out loud now: we have reduced compilation time from 32.5
seconds to 4 seconds. That&rsquo;s an <strong>8x reduction in our compile time</strong>.</p>

<p>A great change taking into account that we&rsquo;ve done changes under 30 lines of
code.</p>

<h2 id="conclusion">Conclusion</h2>

<p>Shapeless is a great library that enables use cases that before were too
difficult for the majority of Scala developers. These use cases save a lot of
boilerplate.</p>

<p>Shapeless has relieved these users from learning macros and getting familiar
with the internals of the compiler to do both basic generic and advanced
typelevel programming in Scala.</p>

<p>However, the techniques used in Shapeless cause slow compilation times and
may give an impression that the Scala compiler is terribly slow. These
techniques are not specific to Shapeless and may happen in other libraries
that use a lot of implicits and macros.</p>

<p>In all these use cases, the slowness is most likely to be caused by a
unintentional misuse of the APIs provided by these frameworks. In this guide,
we have tried to identify what those issues are and how we can get the best
of Shapeless and the compiler without compromising our productivity.</p>

<p>We have learned that automatic typeclass derivation, while powerful and
user-friendly, is likely to materialize implicits for the same type lots of
times.</p>

<p>We have used a new Scala Center tool (<code>scalac-profiling</code>) to profile
implicits and macros to reduce the compile times of
<a href="https://scalacenter.github.io/bloop/">Bloop</a> by <strong>8x</strong>.</p>

<p>Finally, we have gotten a little bit more familiar about the way automatic
typeclass derivation interacts with macro and implicit searches. It is
generally agreed that we need to find a better way to bake generation into
the language to alleviate some of the pitfalls here described.</p>

<p>There&rsquo;s some activity in this area. <a href="https://github.com/scala/scala-dev/issues/445">Adriaan opened a ticket about it several
months ago</a>, and Miles is
backporting the heavy machinery from Shapeless properly into the compiler
(like <a href="https://docs.scala-lang.org/sips/byname-implicits.html">by-name
implicits</a>). I
applaud these efforts.</p>

<p>I believe we still need to find solutions to some of the fundamental problems
of implicit searches and macros. In particular, being more aggressive in
caching macro generated trees and baking into the compiler all the required
knowledge to invalidate caching depending on the kind of macro and call-site.</p>

<p>There&rsquo;s a bright future ahead of us and we are working hard to get there.</p>

<p>In the meanwhile, this blog post aims to provide all the possible data to
alleaviate the compile times of users that leverage automatic typeclass
derivation. I hope this blog post helps make your team more productive with
Scala.</p>

                </section>
            </article>
            <footer id="post-meta" class="clearfix">
                <a href="https://twitter.com/jvican">
                        <img class="avatar" src="https://jvican.github.io/images/avatar.png">
                        <div>
                            <span class="dark">Jorge Vicente Cantero</span>
                            <span>I hack on Scala and devtools.</span>
                        </div>
                    </a>
                <section id="sharing">
                    <a class="twitter" href="https://twitter.com/intent/tweet?text=https%3a%2f%2fjvican.github.io%2fpost%2freduce-compile-times%2f - Reduce%20compile%20times%20of%20macros%20and%20implicits by @jvican"><span class="icon-twitter"> Tweet</span></a>

<a class="facebook" href="#" onclick="
    window.open(
      'https://www.facebook.com/sharer/sharer.php?u='+encodeURIComponent(location.href),
      'facebook-share-dialog',
      'width=626,height=436');
    return false;"><span class="icon-facebook-rect"> Share</span>
</a>

                </section>
            </footer>

            

            <ul id="post-list" class="archive readmore">
    <h3>Read more</h3>

    
    
    
        
        <li>
            <a href="https://jvican.github.io/post/reduce-compile-times/">Reduce compile times of macros and implicits<aside class="dates">May 20</aside></a>
        </li>
        
   
    
        
        <li>
            <a href="https://jvican.github.io/post/git-sbt-analysis/">How often do we change our sbt builds<aside class="dates">Oct 19</aside></a>
        </li>
        
   
    
        
        <li>
            <a href="https://jvican.github.io/post/introduction/">Informal introduction<aside class="dates">Mar 27</aside></a>
        </li>
        
   
</ul>

            <footer id="footer">
    
        <div id="social">

	
	
    
    <a class="symbol" href="https://www.github.com/jvican">
        circlegithub
    </a>
    
    <a class="symbol" href="https://www.twitter.com/jvican">
        circletwitterbird
    </a>
    


</div>

    
    <p class="small">
    
        ¬© Copyright 2018 Jorge Vicente Cantero
    
    </p>
</footer>

        </section>

        <script src="//ajax.googleapis.com/ajax/libs/jquery/2.1.1/jquery.min.js"></script>
<script src="https://jvican.github.io/js/main.js"></script>
<script src="https://jvican.github.io/js/highlight.js"></script>
<script>hljs.initHighlightingOnLoad();</script>





    </body>
</html>
